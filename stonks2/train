#!/usr/bin/env python

import torch
import torch.nn as nn
import csv
import math
import random
import torchvision
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, transforms

input_size = 1
sequence_length=256
num_layers=2
hidden_size=2048
num_classes=1
learning_rate=0.001
batch_size=256
num_epochs=512
prediction_length=7

writer = SummaryWriter()

device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)

class RNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(RNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size,num_classes)

    def forward(self,x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.rnn(x, h0)
        out = out.reshape(out.shape[0], -1)
        out = self.fc(out)
        return out

model = RNN(input_size, hidden_size,num_layers, num_classes).to(device)
print(model)
lossfn = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

def train(i, data, model, lossfn, op):
    model.train()
    X = data[0]
    y = data[1]
    pred = model(X)
    # print(pred.tolist()[:prediction_length])
    loss = lossfn(pred[:prediction_length], y)
    op.zero_grad()
    loss.backward()
    op.step()
    if (i % 100 == 0):
        print(f"i={i} loss={loss.item()}")
        writer.add_scalar('Loss/train', loss.item(), i)

def test(i, data, model, lossfn):
    total_loss = 0
    model.eval()
    with torch.no_grad():
        X = data[0]
        y = data[1]
        pred = model(X)
        loss = lossfn(pred[:prediction_length], y)
        if (i%100==0):
            writer.add_scalar('Loss/test', loss.item(), i)

data=[]
with open(f'spy.csv') as csvf:
    reader = csv.reader(csvf, delimiter=',')
    next(reader,None) # skip header
    for row in reader:
        row = [row[5]]
        row = list(map(lambda x: float(x), row))
        data.append(row)

training_rows = math.floor(len(data)*.8)
test_rows = len(data)-training_rows-prediction_length
print(f"training={training_rows} test={test_rows} total={len(data)}")


X = []
y = []
for i in range(training_rows):
    sequence = torch.tensor(data[i:i+sequence_length+prediction_length]).to(device)
    min = sequence.min()
    sequence -= min
    max = sequence.max()
    sequence /= max
    a,b = sequence.split(sequence_length)
    a = a.unsqueeze(-1)
    X.append(a)
    y.append(b)

test_X=[]
test_y=[]
for i in range(training_rows,training_rows+test_rows):
    sequence = torch.tensor(data[i:i+sequence_length+prediction_length]).to(device)
    min = sequence.min()
    sequence -= min
    max = sequence.max()
    sequence /= max
    print(sequence.size())
    a,b = sequence.split(sequence_length)
    print(a.size(),b.size())
    a = a.unsqueeze(-1)
    test_X.append(a)
    test_y.append(b)

step = 0
while True:
    i = random.randrange(len(X))
    train(step, (X[i],y[i]), model, lossfn, optimizer)
    i = random.randrange(len(test_X))
    test(step, (test_X[i], test_y[i]), model, lossfn, optimizer)
    step+=1
    if (step % 10000 == 0):
        print("saving model!")
        torch.save(model, "model.bin")
    # test(test_X, test_y, model, lossfn)
    
